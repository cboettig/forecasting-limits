---
title: "bad forecast good decision"
author: "Carl Boettiger"
output: github_document
---

```{r}
library(tidyverse)
library(MDPtoolbox)
```


```{r}
states <- seq(0,20, length.out = 200)
actions <- states
obs <- states
sigma_g <- 0.1
reward_fn <- function(x,h) pmin(x,h)
discount <- 0.99

# K is at twice max of f3; 8 * K_3 / 5
f1 <- function(x, h = 0, r = 1, K = 10 * 8 / 5){
  s <- pmax(x - h, 0)
  s + s * (r * (1 - s / K) )
}
f2 <- function(x, h = 0, r = 1, K = 10){
  s <- pmax(x - h, 0)
  s + s * (r * (1 - s / K) )
}

# max is at 4 * K / 5 
f3  <- function(x, h = 0, r = .01, K = 10){
  s <- pmax(x - h, 0)
  s + s ^ 4 * r * (1 - s / K)
}

models <- list(f1, f2, f3)
names(models) <- c("f1", "f2", "f3")
```




```{r}
d <- map_dfc(models, function(f) f(states) - states) %>% mutate(state = states)
d %>% pivot_longer(names(models), "model") %>%
  ggplot(aes(state, value, col=model)) +
  geom_point() + 
  geom_hline(aes(yintercept = 0)) + 
  coord_cartesian(ylim = c(-1, 10), xlim = c(0,16))
```


Comparing forecasts

```{r}
x0 <- 3



```


## Optimal Management

```{r}
# A function to compute the transition matrices for each model:
transition_matrices <- function(f,
                      states,
                      actions,
                      sigma_g){

  n_s <- length(states)
  n_a <- length(actions)

  transition <- array(0, dim = c(n_s, n_s, n_a))
  for (k in 1:n_s) {
    for (i in 1:n_a) {
      nextpop <- f(states[k], actions[i])
      if(nextpop <= 0){
        transition[k, , i] <- c(1, rep(0, n_s - 1))
      } else if(sigma_g > 0){
        x <- dlnorm(states, log(nextpop), sdlog = sigma_g)
        if(sum(x) == 0){ ## nextpop is computationally zero
          transition[k, , i] <- c(1, rep(0, n_s - 1))
        } else {
          N <- plnorm(states[n_s], log(nextpop), sigma_g)
          x <- x * N / sum(x)
          x[n_s] <- 1 - N + x[n_s]
          transition[k, , i] <- x
        }
      } else {
        stop("sigma_g not > 0")
      }
      reward[k, i] <- reward_fn(states[k], actions[i])
    }
  }
  transition
}

## Reward matrix is shared by each model
n_s <- length(states)
n_a <- length(actions)
reward <- array(0, dim = c(n_s, n_a))
for (k in 1:n_s) {
  for (i in 1:n_a) {
    reward[k, i] <- reward_fn(states[k], actions[i])
  }
}

transitions <- lapply(models, function(f) transition_matrices(f, states, actions, sigma_g))

```


Evolution of probability distribution at matrix exponent



```{r}

policies <- map_dfr(transitions, function(P){
  soln <- mdp_value_iteration(P, reward, discount = discount)
  tibble(states, escapement = states - actions[soln$policy])
}, .id = "model")

```


```{r}
policies %>%
  ggplot(aes(states,escapement, col=model)) + geom_line()
```






Management under the wrong model

```{r}


```


## Conclusions

- A good forecast does not mean good management
- A bad forecast does not mean the model is bad for management
- A model permitting successful management does not imply the model is "correct" or generally "good at forecasting"





